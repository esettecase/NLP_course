{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize #from the module nltk.tokenize import the class sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize into a sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"I'm making coffee. Would you like one?\" #initialise the string (variable text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"I'm making coffee.\", 'Would you like one?']\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "token_s = sent_tokenize(text) #create an object tokens and pass the variable text to the function sent_tokenize()\n",
    "print(token_s)\n",
    "print(len(token_s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize a sentence into individual items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', \"'m\", 'making', 'coffee', '.', 'Would', 'you', 'like', 'one', '?']\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "token_w = word_tokenize(text)\n",
    "print(token_w)\n",
    "print(len(token_w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regexp Tokenaisers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'can', 't', 'COME', 'NOW']\n"
     ]
    }
   ],
   "source": [
    "token = RegexpTokenizer('\\w+') # I am looking for any alphanumeric/underscore (more than one! with the +)\n",
    "print(token.tokenize(\"I can't COME NOW.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'can', '’', 't', 'COME', 'NOW', '.']\n"
     ]
    }
   ],
   "source": [
    "token_2= RegexpTokenizer('\\w+|\\S')\n",
    "# \\w [a-zA-Z0-9_] any alphanumeric/underscore\n",
    "# + one or more occurrences of the previous char or expression\n",
    "# | Disjunction (or) \n",
    "# \\S [ˆ\\s] Non-whitespace\n",
    "print(token_2.tokenize(\"I can’t COME NOW.\")) # Now it prints the stop point and the apostrophe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['COME', 'NOW']\n"
     ]
    }
   ],
   "source": [
    "token_3 = RegexpTokenizer('[A-Z]\\w+') # We now select only the CAPITAL LETTERS\n",
    "print(token_3.tokenize(\"I can't COME NOW.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework - Task 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Dutch social psychologist Geert Hofstede uses the concept of power distance to describe how power is distributed and how hierarchy is perceived in different cultures. In her previous work environment, Gabriela was used to a high power distance culture where power and authority are respected and everyone has their rightful place. In such a culture, leaders make the big decisions and are not often challenged. Her Swedish team, however, were used to working in a low power distance culture where subordinates often work together with their bosses to find solutions and make decisions. Here, leaders act as coaches or mentors who encourage independent thought and expect to be challenged.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Dutch social psychologist Geert Hofstede uses the concept of power distance to describe how power is distributed and how hierarchy is perceived in different cultures.',\n",
       " 'In her previous work environment, Gabriela was used to a high power distance culture where power and authority are respected and everyone has their rightful place.',\n",
       " 'In such a culture, leaders make the big decisions and are not often challenged.',\n",
       " 'Her Swedish team, however, were used to working in a low power distance culture where subordinates often work together with their bosses to find solutions and make decisions.',\n",
       " 'Here, leaders act as coaches or mentors who encourage independent thought and expect to be challenged.']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_tokenize(text)\n",
    "#len(sent_tokenize(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework - Task 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"If you \\nthink you can't \\tkeep up-to-date don't @do it! \""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Work tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(text)\n",
    "len(word_tokenize(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) WordPunktTokenizer() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import WordPunctTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['p', '.', 's', '.', 'I', \"'\", 'd', 'love', 'to', 'come', '!']\n"
     ]
    }
   ],
   "source": [
    "text=\"p.s. I'd love to come!\"\n",
    "print(WordPunctTokenizer().tokenize(text))\n",
    "#len(word_tokenize(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Whitespace tokenizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) TreebankWord tokenizer()."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
